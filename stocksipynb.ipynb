{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFGzpzcqDNbGZzLUIniPAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datascientist-ld1981/Finance-StockPrediction-/blob/main/stocksipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STOCK & FINANCES**\n",
        "\n",
        "**Data Collection from Apple Vantage **\n",
        "\n",
        "The program retrieves and merges historical stock price data with detailed financial metrics for a specified company. Using the yfinance library, it fetches stock data, including open, high, low, close prices, and trading volume, over a defined date range. Simultaneously, it utilizes the Alpha Vantage API to collect comprehensive financial details, such as Market Cap, PE Ratio, Revenue, Net Income, Debt to Equity, and Profit Margin. The datasets are then aligned and merged based on the company ticker, creating a unified dataset with both historical and financial insights. Finally, the combined data is saved as a CSV file, enabling streamlined analysis for financial research, backtesting, or machine learning applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "4UW1gSea7rL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj6Ah3FU1aip",
        "outputId": "e262d674-70b0-4995-924c-5a1cf373672f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.51)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "pip install yfinance pandas requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Alpha Vantage API key\n",
        "ALPHA_VANTAGE_API_KEY = \"FCXK9F3UX20DM0RU\"\n",
        "\n",
        "def fetch_stock_price_data(ticker, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Fetch historical stock price data using yfinance.\n",
        "    \"\"\"\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    data.reset_index(inplace=True)\n",
        "    data = data.rename(columns={\n",
        "        \"Open\": \"Open Price\",\n",
        "        \"High\": \"High Price\",\n",
        "        \"Low\": \"Low Price\",\n",
        "        \"Close\": \"Close Price\",\n",
        "        \"Adj Close\": \"Adjusted Close Price\",\n",
        "        \"Volume\": \"Trading Volume\"\n",
        "    })\n",
        "    return data\n",
        "\n",
        "def fetch_alpha_vantage_financials(ticker):\n",
        "    \"\"\"\n",
        "    Fetch additional financial data using Alpha Vantage's OVERVIEW endpoint.\n",
        "    \"\"\"\n",
        "    url = f\"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"OVERVIEW\",\n",
        "        \"symbol\": ticker,\n",
        "        \"apikey\": ALPHA_VANTAGE_API_KEY,\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        financial_data = {\n",
        "            \"Ticker\": ticker,\n",
        "            \"Market Cap\": data.get(\"MarketCapitalization\", \"\"),\n",
        "            \"PE Ratio\": data.get(\"PERatio\", \"\"),\n",
        "            \"Beta\": data.get(\"Beta\", \"\"),\n",
        "            \"EPS (Earnings Per Share)\": data.get(\"EPS\", \"\"),\n",
        "            \"Forward PE\": data.get(\"ForwardPE\", \"\"),\n",
        "            \"Revenue\": data.get(\"RevenueTTM\", \"\"),\n",
        "            \"Gross Profit\": data.get(\"GrossProfitTTM\", \"\"),\n",
        "            \"Operating Income\": data.get(\"OperatingIncomeTTM\", \"\"),\n",
        "            \"Net Income\": data.get(\"NetIncomeTTM\", \"\"),\n",
        "            \"Debt to Equity\": data.get(\"DebtEquityRatio\", \"\"),\n",
        "            \"Return on Equity (ROE)\": data.get(\"ReturnOnEquityTTM\", \"\"),\n",
        "            \"Current Ratio\": data.get(\"CurrentRatio\", \"\"),\n",
        "            \"Dividend Yield\": data.get(\"DividendYield\", \"\"),\n",
        "            \"Free Cash Flow\": data.get(\"FreeCashFlowTTM\", \"\"),\n",
        "            \"Profit Margin\": data.get(\"ProfitMargin\", \"\"),\n",
        "            \"Cash Ratio\": data.get(\"CashRatio\", \"\"),\n",
        "            \"Quick Ratio\": data.get(\"QuickRatio\", \"\"),\n",
        "            \"Price to Book Ratio\": data.get(\"PriceToBookRatio\", \"\"),\n",
        "            \"Enterprise Value\": data.get(\"EnterpriseValue\", \"\"),\n",
        "            \"Total Debt\": data.get(\"TotalDebt\", \"\"),\n",
        "            \"Total Assets\": data.get(\"TotalAssets\", \"\"),\n",
        "            \"Total Equity\": data.get(\"TotalShareholderEquity\", \"\"),\n",
        "            \"Trailing Twelve Months (TTM) Revenue\": data.get(\"RevenueTTM\", \"\"),\n",
        "            \"Trailing Twelve Months (TTM) EBITDA\": data.get(\"EBITDA\", \"\"),\n",
        "            \"Trailing Twelve Months (TTM) Earnings\": data.get(\"NetIncomeTTM\", \"\"),\n",
        "        }\n",
        "        return financial_data\n",
        "    else:\n",
        "        print(f\"Failed to fetch Alpha Vantage data for {ticker}. Status Code: {response.status_code}\")\n",
        "        return {}\n",
        "\n",
        "def merge_data(price_data, financial_data):\n",
        "    \"\"\"\n",
        "    Merge stock price data with financial data.\n",
        "    \"\"\"\n",
        "    if not financial_data:\n",
        "        print(\"No financial data to merge.\")\n",
        "        return price_data\n",
        "\n",
        "    # Ensure price_data has a flat index\n",
        "    if isinstance(price_data.columns, pd.MultiIndex):\n",
        "        price_data.columns = [' '.join(col).strip() for col in price_data.columns.values]\n",
        "\n",
        "    # Convert financial data into a DataFrame\n",
        "    financial_df = pd.DataFrame([financial_data])\n",
        "\n",
        "    # Merge the datasets\n",
        "    merged_data = price_data.merge(financial_df, how=\"left\", left_on=\"Ticker\", right_on=\"Ticker\")\n",
        "    return merged_data\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    ticker = \"AAPL\"  # Example stock ticker for Apple\n",
        "    start_date = \"2022-01-01\"\n",
        "    end_date = \"2023-01-01\"\n",
        "\n",
        "    print(\"Fetching stock price data...\")\n",
        "    price_data = fetch_stock_price_data(ticker, start_date, end_date)\n",
        "    price_data[\"Ticker\"] = ticker  # Add Ticker for merging\n",
        "\n",
        "    print(\"Fetching financial data...\")\n",
        "    financial_data = fetch_alpha_vantage_financials(ticker)\n",
        "\n",
        "    print(\"Merging datasets...\")\n",
        "    final_data = merge_data(price_data, financial_data)\n",
        "\n",
        "    # Save the final dataset to a CSV file\n",
        "    final_data.to_csv(f\"{ticker}_stock_financials.csv\", index=False)\n",
        "    print(f\"Merged dataset saved to {ticker}_stock_financials.csv\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zZoTosS2yIB",
        "outputId": "fde8120f-df08-496b-e29a-d689e24c6e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching stock price data...\n",
            "Fetching financial data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging datasets...\n",
            "Merged dataset saved to AAPL_stock_financials.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**\n"
      ],
      "metadata": {
        "id": "dUt9mMFY7o6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Load the Dataset\n",
        "try:\n",
        "    data = pd.read_csv(\"AAPL_stock_financials.csv\")\n",
        "    if data.empty:\n",
        "        print(\"The dataset is empty. Please provide a valid dataset with data entries.\")\n",
        "        exit()\n",
        "except FileNotFoundError:\n",
        "    print(\"The file 'AAPL_stock_financials.csv' was not found. Please check the file path and name.\")\n",
        "    exit()\n",
        "\n",
        "# 1. Standardize Column Names\n",
        "data.columns = data.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "print(\"Cleaned Column Names:\", data.columns.tolist())\n",
        "\n",
        "# Mapping for required columns\n",
        "column_mapping = {\n",
        "    'open_price_aapl': 'open',\n",
        "    'high_price_aapl': 'high',\n",
        "    'low_price_aapl': 'low',\n",
        "    'close_price_aapl': 'close',\n",
        "    'trading_volume_aapl': 'volume'\n",
        "}\n",
        "\n",
        "# Rename columns based on the mapping\n",
        "data.rename(columns=column_mapping, inplace=True)\n",
        "\n",
        "# 2. Verify Required Columns\n",
        "required_columns = ['open', 'high', 'low', 'close', 'volume']\n",
        "missing_cols = [col for col in required_columns if col not in data.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Missing required columns: {missing_cols}\")\n",
        "    for col in missing_cols:\n",
        "        data[col] = np.nan  # Create missing columns with NaN values.\n",
        "\n",
        "# 3. Handle Missing Values\n",
        "for col in required_columns:\n",
        "    if col in data.columns:\n",
        "        median_value = data[col].median()\n",
        "        data[col] = data[col].fillna(median_value)\n",
        "\n",
        "# 4. Standardize Data Formats\n",
        "if 'date' in data.columns:\n",
        "    data['date'] = pd.to_datetime(data['date'], errors='coerce')\n",
        "    print(\"Date column converted to datetime format.\")\n",
        "\n",
        "data[required_columns] = data[required_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 5. Remove Outliers with Reduced Strictness\n",
        "for col in required_columns:\n",
        "    if col in data.columns:\n",
        "        # Relaxed IQR Multiplier\n",
        "        Q1 = data[col].quantile(0.25)\n",
        "        Q3 = data[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 2.0 * IQR  # Increased multiplier to 2.0\n",
        "        upper_bound = Q3 + 2.0 * IQR\n",
        "\n",
        "        # Filter outliers based on relaxed IQR\n",
        "        initial_count = len(data)\n",
        "        data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
        "        final_count = len(data)\n",
        "        print(f\"Relaxed IQR: Removed {initial_count - final_count} outliers from column '{col}'.\")\n",
        "\n",
        "        # Relaxed Z-Score Threshold\n",
        "        z_scores = stats.zscore(data[col], nan_policy='omit')\n",
        "        data = data[np.abs(z_scores) < 3.5]  # Increased threshold to 3.5\n",
        "\n",
        "# 6. Save the Cleaned Dataset\n",
        "if not data.empty:\n",
        "    data.to_csv(\"AAPL_stock_financials_cleaned.csv\", index=False)\n",
        "    print(\"Data cleaning completed successfully. Cleaned file saved as 'AAPL_stock_financials_cleaned.csv'.\")\n",
        "else:\n",
        "    print(\"Data cleaning resulted in an empty dataset. Please review the data and processing steps.\")\n"
      ],
      "metadata": {
        "id": "Varo3RG37I56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27db535c-c55b-4761-fb95-100856dbfba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Column Names: ['date', 'close_price_aapl', 'high_price_aapl', 'low_price_aapl', 'open_price_aapl', 'trading_volume_aapl', 'ticker', 'market_cap', 'pe_ratio', 'beta', 'eps_(earnings_per_share)', 'forward_pe', 'revenue', 'gross_profit', 'operating_income', 'net_income', 'debt_to_equity', 'return_on_equity_(roe)', 'current_ratio', 'dividend_yield', 'free_cash_flow', 'profit_margin', 'cash_ratio', 'quick_ratio', 'price_to_book_ratio', 'enterprise_value', 'total_debt', 'total_assets', 'total_equity', 'trailing_twelve_months_(ttm)_revenue', 'trailing_twelve_months_(ttm)_ebitda', 'trailing_twelve_months_(ttm)_earnings']\n",
            "Date column converted to datetime format.\n",
            "Relaxed IQR: Removed 0 outliers from column 'open'.\n",
            "Relaxed IQR: Removed 0 outliers from column 'high'.\n",
            "Relaxed IQR: Removed 0 outliers from column 'low'.\n",
            "Relaxed IQR: Removed 0 outliers from column 'close'.\n",
            "Relaxed IQR: Removed 7 outliers from column 'volume'.\n",
            "Data cleaning completed successfully. Cleaned file saved as 'AAPL_stock_financials_cleaned.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9hzFgtC61cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"AAPL_stock_financials_cleaned.csv\")\n",
        "\n",
        "# 1. Check Column Names\n",
        "print(\"Column Names in the Dataset: \", data.columns)\n",
        "\n",
        "# 2. Check if 'close_price_aapl' exists in the dataset\n",
        "if 'close_price_aapl' not in data.columns:\n",
        "    print(\"Error: 'close_price_aapl' column is missing.\")\n",
        "    print(\"Available columns are: \", data.columns)\n",
        "    close_price_available = False\n",
        "else:\n",
        "    close_price_available = True\n",
        "\n",
        "# 3. Descriptive Statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Additional descriptive stats: Mode\n",
        "print(\"\\nMode of each column:\")\n",
        "print(data.mode().iloc[0])  # First row contains the mode for each column\n",
        "\n",
        "# 4. Data Visualization (Only if 'close_price_aapl' exists)\n",
        "\n",
        "if close_price_available:\n",
        "    # Line Chart: Trend in stock prices over time\n",
        "    if 'date' in data.columns:\n",
        "        data['date'] = pd.to_datetime(data['date'])\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(data['date'], data['close_price_aapl'], label='Close Price')\n",
        "        plt.title(\"Trend in Close Prices Over Time\")\n",
        "        plt.xlabel(\"Date\")\n",
        "        plt.ylabel(\"Close Price (AAPL)\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    # Correlation Heatmap (Only numerical columns)\n",
        "    numeric_data = data.select_dtypes(include=[np.number])\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    correlation_matrix = numeric_data.corr()  # Compute correlation only for numeric columns\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title(\"Correlation Heatmap\")\n",
        "    plt.show()\n",
        "\n",
        "    # Box Plots: Detect outliers\n",
        "    for column in ['open_price_aapl', 'high_price_aapl', 'low_price_aapl', 'close_price_aapl', 'trading_volume_aapl']:\n",
        "        if column in data.columns:\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            sns.boxplot(data[column])\n",
        "            plt.title(f\"Box Plot for {column}\")\n",
        "            plt.show()\n",
        "\n",
        "    # Scatter Plot: Stock price vs. volume\n",
        "    if 'close_price_aapl' in data.columns and 'trading_volume_aapl' in data.columns:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.scatterplot(x=data['trading_volume_aapl'], y=data['close_price_aapl'])\n",
        "        plt.title(\"Close Price vs. Trading Volume\")\n",
        "        plt.xlabel(\"Trading Volume\")\n",
        "        plt.ylabel(\"Close Price\")\n",
        "        plt.show()\n",
        "\n",
        "    # Histogram: Distribution of Close Price\n",
        "    data['close_price_aapl'].plot(kind='hist', bins=30, title=\"Distribution of Close Price\", figsize=(8, 4))\n",
        "    plt.xlabel(\"Close Price\")\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation with Close Price\n",
        "    correlation_with_close = correlation_matrix['close_price_aapl'].sort_values(ascending=False)\n",
        "    print(\"\\nFeatures most correlated with Close Price:\\n\", correlation_with_close)\n",
        "\n",
        "# 5. Train-Test Split (Only if 'close_price_aapl' exists)\n",
        "if close_price_available:\n",
        "    # Define features (X) and target (y)\n",
        "    target = 'close_price_aapl'\n",
        "    features = data.drop(columns=[target, 'date'], errors='ignore')  # Drop target and date\n",
        "    X = features\n",
        "    y = data[target]\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)  # No random splitting for time-series\n",
        "    print(\"\\nData split completed. Training samples:\", len(X_train), \"Testing samples:\", len(X_test))\n",
        "\n",
        "    # 6. Normalize Numerical Features\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "    print(\"\\nScaled Feature Sample:\\n\", X_scaled.head())\n",
        "\n",
        "print(\"\\nEDA Completed Successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHr3ZFpeZHme",
        "outputId": "7eb029f7-ad6d-4787-9d1d-22c3dd1cc167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column Names in the Dataset:  Index(['date', 'close', 'high', 'low', 'open', 'volume', 'ticker',\n",
            "       'market_cap', 'pe_ratio', 'beta', 'eps_(earnings_per_share)',\n",
            "       'forward_pe', 'revenue', 'gross_profit', 'operating_income',\n",
            "       'net_income', 'debt_to_equity', 'return_on_equity_(roe)',\n",
            "       'current_ratio', 'dividend_yield', 'free_cash_flow', 'profit_margin',\n",
            "       'cash_ratio', 'quick_ratio', 'price_to_book_ratio', 'enterprise_value',\n",
            "       'total_debt', 'total_assets', 'total_equity',\n",
            "       'trailing_twelve_months_(ttm)_revenue',\n",
            "       'trailing_twelve_months_(ttm)_ebitda',\n",
            "       'trailing_twelve_months_(ttm)_earnings'],\n",
            "      dtype='object')\n",
            "Error: 'close_price_aapl' column is missing.\n",
            "Available columns are:  Index(['date', 'close', 'high', 'low', 'open', 'volume', 'ticker',\n",
            "       'market_cap', 'pe_ratio', 'beta', 'eps_(earnings_per_share)',\n",
            "       'forward_pe', 'revenue', 'gross_profit', 'operating_income',\n",
            "       'net_income', 'debt_to_equity', 'return_on_equity_(roe)',\n",
            "       'current_ratio', 'dividend_yield', 'free_cash_flow', 'profit_margin',\n",
            "       'cash_ratio', 'quick_ratio', 'price_to_book_ratio', 'enterprise_value',\n",
            "       'total_debt', 'total_assets', 'total_equity',\n",
            "       'trailing_twelve_months_(ttm)_revenue',\n",
            "       'trailing_twelve_months_(ttm)_ebitda',\n",
            "       'trailing_twelve_months_(ttm)_earnings'],\n",
            "      dtype='object')\n",
            "\n",
            "Summary Statistics:\n",
            "            close        high         low        open        volume  \\\n",
            "count  244.000000  244.000000  244.000000  244.000000  2.440000e+02   \n",
            "mean   152.850287  154.910926  150.812721  152.870333  8.568354e+07   \n",
            "std     12.760177   12.654002   12.836043   12.793168  1.983714e+07   \n",
            "min    124.728363  128.597677  124.560134  126.658056  3.519590e+07   \n",
            "25%    142.971394  145.128841  140.574163  142.630595  7.152005e+07   \n",
            "50%    152.226479  153.961394  150.104368  152.602274  8.287755e+07   \n",
            "75%    163.560692  166.156235  162.222633  164.308110  9.567025e+07   \n",
            "max    179.076599  179.991620  176.233179  179.686619  1.426898e+08   \n",
            "\n",
            "         market_cap      pe_ratio          beta  eps_(earnings_per_share)  \\\n",
            "count  2.440000e+02  2.440000e+02  2.440000e+02              2.440000e+02   \n",
            "mean   3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "std    0.000000e+00  7.832036e-14  4.227519e-15              1.869009e-14   \n",
            "min    3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "25%    3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "50%    3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "75%    3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "max    3.577065e+12  3.906000e+01  1.240000e+00              6.090000e+00   \n",
            "\n",
            "         forward_pe  ...  cash_ratio  quick_ratio  price_to_book_ratio  \\\n",
            "count  2.440000e+02  ...         0.0          0.0         2.440000e+02   \n",
            "mean   3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "std    1.388406e-13  ...         NaN          NaN         1.495207e-13   \n",
            "min    3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "25%    3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "50%    3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "75%    3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "max    3.185000e+01  ...         NaN          NaN         6.281000e+01   \n",
            "\n",
            "       enterprise_value  total_debt  total_assets  total_equity  \\\n",
            "count               0.0         0.0           0.0           0.0   \n",
            "mean                NaN         NaN           NaN           NaN   \n",
            "std                 NaN         NaN           NaN           NaN   \n",
            "min                 NaN         NaN           NaN           NaN   \n",
            "25%                 NaN         NaN           NaN           NaN   \n",
            "50%                 NaN         NaN           NaN           NaN   \n",
            "75%                 NaN         NaN           NaN           NaN   \n",
            "max                 NaN         NaN           NaN           NaN   \n",
            "\n",
            "       trailing_twelve_months_(ttm)_revenue  \\\n",
            "count                          2.440000e+02   \n",
            "mean                           3.910350e+11   \n",
            "std                            0.000000e+00   \n",
            "min                            3.910350e+11   \n",
            "25%                            3.910350e+11   \n",
            "50%                            3.910350e+11   \n",
            "75%                            3.910350e+11   \n",
            "max                            3.910350e+11   \n",
            "\n",
            "       trailing_twelve_months_(ttm)_ebitda  \\\n",
            "count                         2.440000e+02   \n",
            "mean                          1.346610e+11   \n",
            "std                           0.000000e+00   \n",
            "min                           1.346610e+11   \n",
            "25%                           1.346610e+11   \n",
            "50%                           1.346610e+11   \n",
            "75%                           1.346610e+11   \n",
            "max                           1.346610e+11   \n",
            "\n",
            "       trailing_twelve_months_(ttm)_earnings  \n",
            "count                                    0.0  \n",
            "mean                                     NaN  \n",
            "std                                      NaN  \n",
            "min                                      NaN  \n",
            "25%                                      NaN  \n",
            "50%                                      NaN  \n",
            "75%                                      NaN  \n",
            "max                                      NaN  \n",
            "\n",
            "[8 rows x 30 columns]\n",
            "\n",
            "Mode of each column:\n",
            "date                                          2022-01-03\n",
            "close                                         139.759537\n",
            "high                                          128.597677\n",
            "low                                           124.560134\n",
            "open                                          126.658056\n",
            "volume                                          35195900\n",
            "ticker                                              AAPL\n",
            "market_cap                               3577065243000.0\n",
            "pe_ratio                                           39.06\n",
            "beta                                                1.24\n",
            "eps_(earnings_per_share)                            6.09\n",
            "forward_pe                                         31.85\n",
            "revenue                                   391034995000.0\n",
            "gross_profit                              180682998000.0\n",
            "operating_income                                     NaN\n",
            "net_income                                           NaN\n",
            "debt_to_equity                                       NaN\n",
            "return_on_equity_(roe)                             1.574\n",
            "current_ratio                                        NaN\n",
            "dividend_yield                                    0.0042\n",
            "free_cash_flow                                       NaN\n",
            "profit_margin                                       0.24\n",
            "cash_ratio                                           NaN\n",
            "quick_ratio                                          NaN\n",
            "price_to_book_ratio                                62.81\n",
            "enterprise_value                                     NaN\n",
            "total_debt                                           NaN\n",
            "total_assets                                         NaN\n",
            "total_equity                                         NaN\n",
            "trailing_twelve_months_(ttm)_revenue      391034995000.0\n",
            "trailing_twelve_months_(ttm)_ebitda       134660997000.0\n",
            "trailing_twelve_months_(ttm)_earnings                NaN\n",
            "Name: 0, dtype: object\n",
            "\n",
            "EDA Completed Successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection**\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "XGBoost\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Decision Trees"
      ],
      "metadata": {
        "id": "n1o2rIJW-hE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"AAPL_stock_financials_cleaned.csv\")\n",
        "\n",
        "# Check if 'close' column exists\n",
        "if 'close' not in data.columns:\n",
        "    print(\"Error: 'close' column is missing.\")\n",
        "    print(\"Available columns are: \", data.columns)\n",
        "else:\n",
        "    target = 'close'  # Use 'close' as the target variable\n",
        "\n",
        "    # Feature selection: Drop 'close' and 'date', ensure numerical columns are selected\n",
        "    features = data.drop(columns=[target, 'date'], errors='ignore')  # Drop 'close' and 'date'\n",
        "\n",
        "    # Filter to keep only numeric columns\n",
        "    features = features.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Handle missing values by imputing with the median\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "    # Define X and y\n",
        "    X = features_imputed\n",
        "    y = data[target].dropna()  # Ensure target doesn't have missing values\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)  # Time series split\n",
        "\n",
        "    # Normalize features using MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Model selection\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "        \"Gradient Boosting Regressor\": GradientBoostingRegressor()\n",
        "    }\n",
        "\n",
        "    # Train and evaluate models using cross-validation\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        score = model.score(X_test_scaled, y_test)\n",
        "        print(f\"{model_name} R^2 score on test set: {score:.4f}\")\n",
        "\n",
        "    # Hyperparameter tuning for Random Forest using GridSearchCV\n",
        "    rf_model = RandomForestRegressor()\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "    print(f\"\\nBest parameters for Random Forest: {grid_search.best_params_}\")\n",
        "\n",
        "    # Final evaluation with the best Random Forest model\n",
        "    best_rf_model = grid_search.best_estimator_\n",
        "    best_rf_score = best_rf_model.score(X_test_scaled, y_test)\n",
        "    print(f\"Best Random Forest Model R^2 score: {best_rf_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fodfIExk-8M9",
        "outputId": "ba60c0ec-9576-42d3-80fe-659aebef4977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['operating_income' 'net_income' 'debt_to_equity' 'current_ratio'\n",
            " 'free_cash_flow' 'cash_ratio' 'quick_ratio' 'enterprise_value'\n",
            " 'total_debt' 'total_assets' 'total_equity'\n",
            " 'trailing_twelve_months_(ttm)_earnings']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Linear Regression...\n",
            "Linear Regression R^2 score on test set: 0.9761\n",
            "\n",
            "Training Decision Tree Regressor...\n",
            "Decision Tree Regressor R^2 score on test set: 0.8902\n",
            "\n",
            "Training Random Forest Regressor...\n",
            "Random Forest Regressor R^2 score on test set: 0.9288\n",
            "\n",
            "Training Gradient Boosting Regressor...\n",
            "Gradient Boosting Regressor R^2 score on test set: 0.9417\n",
            "\n",
            "Best parameters for Random Forest: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best Random Forest Model R^2 score: 0.9305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Flow Tracking**"
      ],
      "metadata": {
        "id": "0j8fqpv_IsWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew6ViE-Y69xy",
        "outputId": "0d37ccd2-756d-4885-da73-2a359eceaa7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.19.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==2.19.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-2.19.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.5)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (17.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.6.0)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.37)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (8.1.8)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.0)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.19.0->mlflow)\n",
            "  Downloading databricks_sdk-0.40.0-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (3.1.44)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (1.29.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (24.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (4.25.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.19.0->mlflow) (0.5.3)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.19.0->mlflow) (3.21.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (0.50b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.19.0->mlflow) (2024.12.14)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-2.19.0-py3-none-any.whl (27.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-2.19.0-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.40.0-py3-none-any.whl (629 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m629.7/629.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, gunicorn, graphql-core, graphql-relay, docker, alembic, graphene, databricks-sdk, mlflow-skinny, mlflow\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 databricks-sdk-0.40.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.19.0 mlflow-skinny-2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Start MLflow experiment\n",
        "mlflow.start_run()\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"AAPL_stock_financials_cleaned.csv\")\n",
        "\n",
        "# Check if 'close' column exists\n",
        "if 'close' not in data.columns:\n",
        "    print(\"Error: 'close' column is missing.\")\n",
        "    print(\"Available columns are: \", data.columns)\n",
        "else:\n",
        "    target = 'close'  # Use 'close' as the target variable\n",
        "\n",
        "    # Feature selection: Drop 'close' and 'date', ensure numerical columns are selected\n",
        "    features = data.drop(columns=[target, 'date'], errors='ignore')  # Drop 'close' and 'date'\n",
        "\n",
        "    # Filter to keep only numeric columns\n",
        "    features = features.select_dtypes(include=[np.number])\n",
        "\n",
        "    # Handle missing values by imputing with the median\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "    # Define X and y\n",
        "    X = features_imputed\n",
        "    y = data[target].dropna()  # Ensure target doesn't have missing values\n",
        "\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)  # Time series split\n",
        "\n",
        "    # Normalize features using MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Model selection\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "        \"Gradient Boosting Regressor\": GradientBoostingRegressor()\n",
        "    }\n",
        "\n",
        "    # Train and evaluate models using cross-validation\n",
        "    for model_name, model in models.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        score = model.score(X_test_scaled, y_test)\n",
        "        print(f\"{model_name} R^2 score on test set: {score:.4f}\")\n",
        "\n",
        "        # Log metrics to MLflow\n",
        "        mlflow.log_metric(f\"{model_name}_R2\", score)\n",
        "\n",
        "        # Log model with input example for signature inference\n",
        "        example_input = X_train_scaled[:1]  # First sample as an example input\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\", input_example=example_input)\n",
        "\n",
        "    # Hyperparameter tuning for Random Forest using GridSearchCV\n",
        "    rf_model = RandomForestRegressor()\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],\n",
        "        'max_depth': [10, 20],\n",
        "        'min_samples_split': [2, 5],\n",
        "        'min_samples_leaf': [1, 2]\n",
        "    }\n",
        "    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "    print(f\"\\nBest parameters for Random Forest: {grid_search.best_params_}\")\n",
        "\n",
        "    # Final evaluation with the best Random Forest model\n",
        "    best_rf_model = grid_search.best_estimator_\n",
        "    best_rf_score = best_rf_model.score(X_test_scaled, y_test)\n",
        "    print(f\"Best Random Forest Model R^2 score: {best_rf_score:.4f}\")\n",
        "\n",
        "    # Log best Random Forest model\n",
        "    example_input = X_train_scaled[:1]  # First sample as an example input\n",
        "    mlflow.sklearn.log_model(best_rf_model, \"best_rf_model\", input_example=example_input)\n",
        "\n",
        "# End MLflow experiment\n",
        "mlflow.end_run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHhQA7PHI3qJ",
        "outputId": "b289d192-97b9-4491-bd2f-239e28255edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['operating_income' 'net_income' 'debt_to_equity' 'current_ratio'\n",
            " 'free_cash_flow' 'cash_ratio' 'quick_ratio' 'enterprise_value'\n",
            " 'total_debt' 'total_assets' 'total_equity'\n",
            " 'trailing_twelve_months_(ttm)_earnings']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Linear Regression...\n",
            "Linear Regression R^2 score on test set: 0.9761\n",
            "\n",
            "Training Decision Tree Regressor...\n",
            "Decision Tree Regressor R^2 score on test set: 0.8982\n",
            "\n",
            "Training Random Forest Regressor...\n",
            "Random Forest Regressor R^2 score on test set: 0.9306\n",
            "\n",
            "Training Gradient Boosting Regressor...\n",
            "Gradient Boosting Regressor R^2 score on test set: 0.9388\n",
            "\n",
            "Best parameters for Random Forest: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Random Forest Model R^2 score: 0.9330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIAR8YAw1XX_",
        "outputId": "89e6e6c1-0260-43be-d207-b2890f4580dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.41.1-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.41.1-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.41.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Streamlit Incoporating**\n",
        "Executed in Visual code by svaing in .py file and running in virtual environment"
      ],
      "metadata": {
        "id": "TkH69hs_Z2C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Stock Price Prediction System\")\n",
        "st.write(\"Predict closing stock prices using machine learning models.\")\n",
        "uploaded_file = st.file_uploader(\"Upload your dataset (CSV)\", type=[\"csv\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(uploaded_file)\n",
        "    st.write(\"Preview of the Dataset:\", data.head())\n",
        "\n",
        "    if 'close' not in data.columns:\n",
        "        st.error(\"'close' column is missing. Please upload a dataset with the 'close' column.\")\n",
        "    else:\n",
        "        # Start MLflow experiment\n",
        "        mlflow.start_run()\n",
        "\n",
        "        # Target variable\n",
        "        target = 'close'\n",
        "\n",
        "        # Feature selection\n",
        "        features = data.drop(columns=[target, 'date'], errors='ignore')\n",
        "        features = features.select_dtypes(include=[np.number])\n",
        "\n",
        "        # Handle missing values\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        features_imputed = imputer.fit_transform(features)\n",
        "\n",
        "        # Define X and y\n",
        "        X = features_imputed\n",
        "        y = data[target].dropna()\n",
        "\n",
        "        # Train-Test Split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "        # Normalize features\n",
        "        scaler = MinMaxScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Model selection\n",
        "        models = {\n",
        "            \"Linear Regression\": LinearRegression(),\n",
        "            \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "            \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "            \"Gradient Boosting Regressor\": GradientBoostingRegressor()\n",
        "        }\n",
        "\n",
        "        st.write(\"### Model Performance\")\n",
        "        results = []\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            score = model.score(X_test_scaled, y_test)\n",
        "            results.append({\"Model\": model_name, \"R² Score\": round(score, 4)})\n",
        "\n",
        "            # Log metrics and models\n",
        "            mlflow.log_metric(f\"{model_name}_R2\", score)\n",
        "            example_input = X_train_scaled[:1]\n",
        "            mlflow.sklearn.log_model(model, f\"{model_name}_model\", input_example=example_input)\n",
        "\n",
        "        # Display results\n",
        "        st.dataframe(results)\n",
        "\n",
        "        # Hyperparameter tuning for Random Forest\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [10, 20],\n",
        "            'min_samples_split': [2, 5],\n",
        "            'min_samples_leaf': [1, 2]\n",
        "        }\n",
        "        rf_model = RandomForestRegressor()\n",
        "        grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "        best_rf_model = grid_search.best_estimator_\n",
        "        best_rf_score = best_rf_model.score(X_test_scaled, y_test)\n",
        "        st.write(f\"Best Random Forest R² Score: {best_rf_score:.4f}\")\n",
        "        st.write(\"Best Parameters for Random Forest:\", grid_search.best_params_)\n",
        "\n",
        "        # Log the best model\n",
        "        mlflow.sklearn.log_model(best_rf_model, \"best_rf_model\", input_example=X_train_scaled[:1])\n",
        "\n",
        "        # End MLflow experiment\n",
        "        mlflow.end_run()\n",
        "\n",
        "        st.success(\"Experiment completed and logged to MLflow!\")\n",
        "\n",
        "else:\n",
        "    st.info(\"Please upload a dataset to begin.\")\n",
        "\n",
        "# To run this script in Colab:\n",
        "# 1. Install Streamlit and pyngrok (`!pip install streamlit pyngrok`).\n",
        "# 2. Run Streamlit in the background (`!streamlit run your_script.py &`).\n",
        "# 3. Use ngrok to tunnel your Streamlit app (`!ngrok http 8501`).\n"
      ],
      "metadata": {
        "id": "6_9-RvEtaceL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}